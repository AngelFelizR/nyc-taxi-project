---
title: "Data Collection Process"
format: 
  gfm:
    toc: true

execute:
  message: false
  warning: false
---

For most projects the data collection process can be done manually and later attache the file in the `data` folder but that isn't a option when we are working with big data.

To solve this problem, we have created the next script to automate the data collection process so the project could be reproduced easily just by running the code below.

## Web Scraping

To always have a updated list of 2022 and 2023 links of **High Volume For-Hire Vehicles** documents let's scrape the [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) by using the `rvest` library.

```{r}
SourcePage <-
  rvest::read_html("https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page")

TripLinks <-
  SourcePage |>
  rvest::html_elements(xpath = '//div[@class="faq-answers"]//li/a') |>
  rvest::html_attr("href") |>
  grep(pattern = "fhvhv_[a-z]+_202[23]-\\d{2}\\.parquet", value = TRUE) |>
  trimws() |>
  sort()

basename(TripLinks) 
```

From the same page we also can find the link to download the codes related to each Zone.

```{r}
TaxiZoneLink <-
  SourcePage |>
  rvest::html_elements(xpath = '//ul/li/a[text()="Taxi Zone Lookup Table"]')  |>
  rvest::html_attr("href") |>
  trimws()
```

## Saving files

As we have many files

```{r}

# 2. Downloading each file ----

# Creating data dir if missing
if(!"data" %in% dir()) dir.create("data")
if(!"trip-data" %in% dir("data")) dir.create("data/trip-data")

## Defining the path to save files
TripLocalPath <- file.path("data","trip-data", basename(TripLinks))

## This will make sure that R won't stop before
## downloading each parquet file
options(timeout = 1800)

## Saving Trip Parquet files
## using he wb mode to download binaries
for(link_i in seq_along(TripLinks)){
  download.file(TripLinks[link_i],
                destfile = TripLocalPath[link_i],
                mode = "wb")
}

## Saving Taxi Zone CSV
download.file(TaxiZoneLink,
              destfile = file.path("data","taxi_zone_lookup.csv"),
              mode = "wb")


# 3. Splitting training and testing data ----

## As we a lot of data we can use 3 moths for training
## the rest of the months for testing the results
FilePathTrain <- head(TripLocalPath, 3L)
FilePathTest <- tail(TripLocalPath, 3L)

## Down sampling training and testing data to 5% of rows
## To mitigate the current computational limitations
TotalRows <-
  arrow::open_dataset(here::here("data/trip-data")) |>
  nrow()

DownSampleRows <- as.integer(TotalRows*0.05/2)

## Saving training set
set.seed(202301)
FilePathTrain |>
  lapply(\(x) data.table::as.data.table(arrow::read_parquet(x))) |>
  data.table::rbindlist() |>
  (\(dt) dt[sample.int(n = nrow(dt), size = DownSampleRows)])() |>
  fst::write_fst("data/TripDataTrain.fst")
gc()

## Saving testing set
set.seed(202302)
FilePathTest |>
  lapply(\(x) data.table::as.data.table(arrow::read_parquet(x))) |>
  data.table::rbindlist() |>
  (\(dt) dt[sample.int(n = nrow(dt), size = DownSampleRows)])() |>
  fst::write_fst("data/TripDataTest.fst")
gc()

set.seed(NULL)

```

