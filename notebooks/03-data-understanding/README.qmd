---
title: "Exploratory Data Analysis (EDA) of 2022 High Volume For-Hire Vehicles"
format: 
  gfm:
    toc: true

execute:
  message: false
  warning: false
---

After completing the [business understanding](https://github.com/AngelFelizR/nyc-taxi-project/tree/master/notebooks/02-business-understanding) step, we have a clear objective in mind and an initial description for each column the [raw data](https://github.com/AngelFelizR/nyc-taxi-project/tree/master/data), we are ready to perform the *data understanding* by performing an EDA with the following steps:

1. Examining the distribution of each individual variable by counting the categorical variables and creating histograms or box plots for numerical variables
2. Confirming domain knowledge relations by creating visualization with 2 or more variables
3. Taking a subset of the data to fit in RAM
4. Defining the target variable and confirming its distribution
5. Exploring correlations between predictors by using a correlation matrix or running a PCA
6. Removing high correlated predictors
7. Exploring correlations between the target and predictors creating a correlation funnel and some scatter plots.

After completing this process, we will have the following outcomes:

- Confirming the meaning of each variable
- Ensuring data quality by finding missing values and 
- Identifying the best models to train
- Creating new features that can enhance the predictive power of the machine learning model


## Setting the environment up

To setting the `R` environment up we just need to apply the following 4 steps:

1. Loading the packages to use.

```{r}
library(here)
library(data.table)
library(ggplot2)
library(scales)
library(forcats)
library(dplyr)
library(arrow)
```

2. Sourcing some custom functions created to avoid repeating myself.

```{r}
source(here("R/01-custom-functions.R"))
```

3. Creating an Arrow connection object to perform some manipulations in disk before taking the data into the RAM memory.

```{r}
NycTrips2022 <- 
  here("data/trip-data/year=2022") |>
  open_dataset() |>
  mutate(company = case_when(
    hvfhs_license_num == "HV0002" ~ "Juno",
    hvfhs_license_num == "HV0003" ~ "Uber",
    hvfhs_license_num == "HV0004" ~ "Via",
    hvfhs_license_num == "HV0005" ~ "Lyft"
  )) |>
  select(-hvfhs_license_num)
```

4. Importing the zone code description.

```{r}
ZoneCodes <- fread(
  here("data/taxi_zone_lookup.csv"),
  colClasses = c("integer", "character", "character", "character")
)
```

## Exploring distribution of each individual variable

### Categorical variables

- `company`: The majority number of trips are done by *Uber* (HV003) and the rest for *Lyft*.

```{r}
NycTrips2022 |> count_pct(company)
```

- `dispatching_base_num`: This column doesn't show much information, so we will **erase** this column as it doesn't show any useful information.

```{r}
NycTrips2022 |> count_pct(dispatching_base_num)
```

- `originating_base_num`: This column doesn't show much information, so we will **erase** this column as it doesn't show any useful information.

```{r}
NycTrips2022 |> count_pct(originating_base_num)
```

- `shared_request_flag`: Most of passengers don't agree to a shared/pooled ride.

```{r}
NycTrips2022 |> count_pct(shared_request_flag)
```

- `shared_match_flag`: Shows that actually fewer trips were shared.

```{r}
NycTrips2022 |> count_pct(shared_match_flag)
```

- `access_a_ride_flag`: *Uber* isn't reporting whether their trips were administered on behalf of the Metropolitan Transportation Authority and for *Lyft* the answer is always "N", so we will **erase** this column as it doesn't show any useful information.

```{r}
NycTrips2022 |> count_pct(company, access_a_ride_flag)
```

- `wav_request_flag`: It's really unusual for a passager to request a wheelchair-accessible vehicle.

```{r}
NycTrips2022 |> count_pct(wav_request_flag)
```

- `wav_match_flag`: 7% of trips took place in wheelchair-accessible vehicle which implies that there is more offers than demand.

```{r}
NycTrips2022 |> count_pct(wav_match_flag)
```

To explore the distribution of trips based start and end locations let's define a table and then explain the analysis into more plots.

```{r}
TripsLocationSummary <-
  NycTrips2022 |>
  count(PULocationID, DOLocationID) |>
  collect() |>
  join_zones(zone_tb = ZoneCodes)
```

- `start_borough` and `end_borough`: 

```{r}
TripsLocationSummary[, .(n = sum(n)),
                     by = c("start_borough", "end_borough")
  ][order(n)
  ][, c("start_borough", "end_borough") := 
      lapply(.SD, \(x) factor(x, levels = unique(x, fromLast = TRUE)) ),
    .SDcols = c("start_borough", "end_borough")
  ][, end_borough := fct_rev(end_borough)] |>
  ggplot(aes(end_borough, start_borough))+
  geom_tile(aes(fill = n)) +
  geom_text(aes(label = percent(n/sum(n), accuracy = 0.01))) +
  scale_fill_gradient(low = "white", 
                      high = "red",
                      labels= comma_format())+
  scale_x_discrete(position = "top") +
  labs(title = "Distribution of Trips by Borough in NYC 2022",
       x = "Trip End", 
       y = "Trip Start", 
       fill = "Number of Trips") +
  theme_classic() +
  theme(plot.title = element_text(face = "bold"),
        axis.ticks = element_blank(),
        axis.line = element_blank(),
        axis.text = element_text(color = "black"),
        axis.title = element_text(face = "italic"))
```

