---
title: "Data Collection Process"
format: 
  gfm:
    toc: true

execute:
  message: false
  warning: false
---

For most projects the data collection process can be done manually and later attache the file in the `data` folder but that isn't a option when we are working with big data.

To solve this problem, we have created the next script to automate the data collection process so the project could be reproduced easily just by running the code below.

## Web Scraping

To always have a updated list of 2022 and 2023 links of **High Volume For-Hire Vehicles** documents let's scrape the [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page) by using the `rvest` library.

```{r}
SourcePage <-
  rvest::read_html("https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page")

TripLinks <-
  SourcePage |>
  rvest::html_elements(xpath = '//div[@class="faq-answers"]//li/a') |>
  rvest::html_attr("href") |>
  grep(pattern = "fhvhv_[a-z]+_202[23]-\\d{2}\\.parquet", value = TRUE) |>
  trimws() |>
  sort()

FileNames <- basename(TripLinks)

FileNames
```

From the same page we also can find the link to download the codes related to each Zone.

```{r}
TaxiZoneLink <-
  SourcePage |>
  rvest::html_elements(xpath = '//ul/li/a[text()="Taxi Zone Lookup Table"]')  |>
  rvest::html_attr("href") |>
  trimws()
```

## Saving files

To take advantage of the best capacities of `arrow` we need save a each parquet file in folder with useful information to filter later, that why we will have one folder level related to years the next sub-folders related to a month with each parquet with the name `part-0.parquet`

Let's start creating a folder to store all the parquet files.

```{r}
ParquetFolderPath <- file.path("data", "trip-data")

dir.create(ParquetFolderPath, showWarnings  = FALSE)

ParquetFolderPath
```

Then we need to define the sub-folders to split the files based on year.

```{r}
YearFolders <- gsub(
  x = FileNames,
  pattern = "^fhvhv_tripdata_|-\\d{2}\\.parquet$",
  replacement = ""
) |>
  paste0("year=", a = _)

YearFoldersUnique <- unique(YearFolders)
YearFoldersPath <- file.path(ParquetFolderPath, YearFoldersUnique)

for(year_i in YearFoldersPath) dir.create(year_i)

YearFoldersPath
```

Once created we just need to create the de month folder.

```{r}
MonthFolders <- gsub(
  x = FileNames,
  pattern = "^fhvhv_tripdata_\\d{4}-|\\.parquet$",
  replacement = ""
) |>
  paste0("month=", a = _)

MonthFoldersPath <- file.path(ParquetFolderPath, YearFolders, MonthFolders)

for(month_i in MonthFoldersPath) dir.create(month_i, showWarnings = FALSE)

MonthFoldersPath

```

Finally, we just need to download each file on each folder.

```{r}
#| eval: false


# Parquet files might time a longer time to be downloaded
options(timeout = 1800)


# Parquet trip data
for(link_i in seq_along(TripLinks)){
  
  download.file(TripLinks[link_i],
                destfile = file.path(MonthFoldersPath[link_i],"part-0.parquet"),
                mode = "wb")
  
}


# Taxi Zone CSV
download.file(TaxiZoneLink,
              destfile = file.path("data","taxi_zone_lookup.csv"),
              mode = "wb")

```


## Final result

After getting all the files you should end with the next structure for the `data` folder.

```{r}
fs::dir_tree(here::here("data"))
```

