---
title: "NYC Trip - Exploratory Data Analysis"
output-file: "README.md"
format: gfm
execute:
  message: false
  warning: false
bibliography: reference.bib
---

## Description

Although the primary objective of this project is to **predict the tips** that taxi drivers receive from passengers, it's crucial to have a comprehensive understanding of the data to **avoid drawing incorrect conclusions**. To achieve this, we will perform the following steps:

1. **Explore the distribution of each individual variable** to understand what is typical or atypical and identify data quality issues.
2. **Validate domain knowledge assumptions** to uncover data quality problems or correct erroneous assumptions that could potentially affect our final conclusions.
3. **Create new features** based on domain knowledge to enhance the likelihood of discovering valuable insights.
4. **Impute missing values** to prevent introducing bias.
5. **Use PCA and EFA** to understand the correlation between features.


## Setting Up The Environment

1. Loading main packages

```{r load-packages}
library(here)
library(data.table)
library(lubridate)
library(ggplot2)
library(scales)
library(patchwork)
theme_set(theme_light())

source(here("01-EDA/00-custom-functions.R"))
```

2. Importing data from January to March as our training data with **56,853,541 rows** corresponding to **10 GB**.

```{r import-raw-data}
TripDataTrain <- fst::read_fst(
  path = here("00-data/TripDataTrain.fst"),
  as.data.table = TRUE
)

TripDataDim <- dim(TripDataTrain)
comma(TripDataDim)
```

3. Downsampling the data to **17,000,000 rows** to solve memory limitation problems, but keeping a **representative sample** of the population.

```{r sampling-data}
set.seed(20230922)
TripDataTrain <- TripDataTrain[sample.int(TripDataDim[1L],17e6)]

TripDataDim <- dim(TripDataTrain)
comma(TripDataDim)
```

4. Decoding data based on dictionary information.

```{r decoding-zone-codes}
TripDataTrain <- decode_cols(
  trip_table = TripDataTrain,
  zone_path = here("00-data/taxi_zone_lookup.csv")
)
```

## 1. Variable Distribution

To avoid spending too much time on this step, use the same visualization based on the variable's type.

### Categorical Variables Distribution

```{r cat-distribution}
cat_vars <- TripDataTrain[, names(.SD), .SDcols = is.character]

for(cat_i in cat_vars){
  TripDataTrain[, .(count = .N), 
                by = cat_i
  ][, pct_count := round(count/sum(count)*100, 2)
  ][order(-count)] |>
  print()
}

```

#### Findings

By counting the rows by category for each row, we found that:

- We can **remove** the `dispatching_base_num` and `originating_base_num` as their information is very close to the `hvfhs_license_num`, and their other values only represent **0.02%** of the rows.

- Based on `shared_request_flag` and `shared_match_flag`, we know that most of the passengers **agree to share the ride** even if other passengers booked separately.

- Based on `access_a_ride_flag`, we know that most of the **trips were administered by MTA**. We also found that the field is missing the "Y" flag.

- Based on `wav_request_flag` and `wav_match_flag`, we know that only **0.16%** of trips requested a wheelchair-accessible vehicle, but **6.84%** of trips had that capacity, which is really good news.

- In the `PU_Borough` and `DO_Borough` columns, very few trips pass through "Staten Island", "Unknown", or "EWR", so we will consolidate them as "Other".

- `PU_Zone` and `DO_Zone` have too many categories, and we don't need them for this process.

- As "EWR" represents the **Newark Liberty International Airport** and represents very few trips, we can consolidate this category to the more general one "Airports" for the `PU_service_zone` and `DO_service_zone` columns.

### Numerical Variables Distribution

To validate numeric variables we are potting at original and logarithmic scale.

```{r num-distribution}
num_vars <- TripDataTrain[, names(.SD), .SDcols = is.numeric]

for(num_i in num_vars){
  
 print(custom_histogram(TripDataTrain, num_i))

}

```

#### Findings

After exploring the histogram of each variable, we found that:

- **`r TripDataTrain[trip_miles == 0, comma(.N)]`** trips have 0 miles, which doesn't make much sense unless the that the trip started and ended at the same location, otherwise these values should be label as `NA`.




### Datetime Variables Distribution

To validate numeric variables we are potting at normal and logarithmic scale.

```{r}
date_vars <- TripDataTrain[, names(.SD), .SDcols = is.POSIXct]

for(date_i in date_vars){
  
  date_hist <-
    ggplot(TripDataTrain, aes(get(date_i)))+
    geom_histogram(fill = "blue",
                   color = "black",
                   alpha = 0.8,
                   bins = 30)+
    labs(title = paste0(date_i, " Distribution"),
         x = date_i)
  
  print(date_hist)
}

```


## Domain

![Green and Yellow Zones from : https://www.new-york-city-travel-tips.com/green-cab-new-york-boro-taxi/](01-Green-Yellow-Zones.png)



```{r}
TripDataTrain[trip_miles == 0,
              .N,
              keyby = .(same_service_zone = PU_service_zone == DO_service_zone,
                        same_Borough = PU_Borough == DO_Borough,
                        same_Zone = PU_Zone == DO_Zone)]


TripDataTrain[trip_miles == 0 &
                PU_Zone != DO_Zone &
                ((PU_service_zone != DO_service_zone &
                    PU_Borough == DO_Borough) |
                   (PU_service_zone == DO_service_zone &
                      PU_Borough != DO_Borough)),
              .SD,
              .SDcols = patterns("PU_|DO_")] |>
  View()

```


```{r}
library(tidygeocoder)
library(osrm)
library(leaflet)

# Define the locations
data <- data.frame(adress = c("JFK Airport, Queens, NY, US",
                              "Briarwood/Jamaica Hills, Queens, NY, US"))

# Geocode the locations using Nominatim
geo1 <- tidygeocoder::geocode(data, address = "adress", method = "osm")

geo2 <- tidygeocoder::geocode(data, address = "adress", method = "arcgis")

# Calculate the distance
dist2 <- osrm::osrmRoute(src = c(geo2$long[1], geo2$lat[1]), dst = c(geo2$long[2], geo2$lat[2]), overview = "full")

# Print the distance in miles
print(dist2$distance * 0.621371)

install.packages("leaflet")
library(leaflet)

# Create a leaflet map
m <- leaflet() |>
  addTiles() |>
  addPolylines(data = dist2$geometry,
               color = "blue")

# Print the map
print(m)

```


